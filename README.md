# ğŸ¤– AI Assistant with Ollama 

*A conversational AI assistant powered by local LLMs (LLaMA, etc.) and a sleek Streamlit web interface.*

<div align="center">
  <img src="assets/img1.png" alt="Interface Demo" width="45%">
  <img src="assets/img2.png" alt="Model Switching" width="45%">
</div>

## âœ¨ Features  
- ğŸ’¬ Human-like Q&A using Ollama's local models (supports LLaMA, Mistral, etc.)  
- ğŸ–¥ï¸ Streamlit-based web UI for easy interaction  
- âš¡ Test/switch models on the fly (see demo above â†’)  
- ğŸ§¹ Chat history management  
- ğŸ”Œ Simple API-like connection testing  

## ğŸ› ï¸ Tech Stack  
- **Ollama** (for local model inference)  
- **Streamlit** (frontend interface)  
- **Python 3.10+**  